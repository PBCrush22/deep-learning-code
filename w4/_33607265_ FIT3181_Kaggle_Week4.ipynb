{"cells":[{"cell_type":"markdown","metadata":{"id":"DHNAq9QI7vQn"},"source":["# Tutorial 4: CNN and Kaggle competition"]},{"cell_type":"markdown","metadata":{"id":"uIg_vVMU_pU4"},"source":["### <span style=\"color:#0b486b\"> II.0 Running on Google Colab</span> <span style=\"color:red\"></span>\n","You will need to download relevant files to run this notebook on Google Colab."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2890,"status":"ok","timestamp":1723776586163,"user":{"displayName":"Hanyu Beh","userId":"09674366287163471345"},"user_tz":-480},"id":"LUu6Lil9FUsi","outputId":"2fac56b1-e54a-463a-98ae-ccda211306b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Failed to retrieve file url:\n","\n","\tToo many users have viewed or downloaded this file recently. Please\n","\ttry accessing the file again later. If the file you are trying to\n","\taccess is particularly large or is shared with many people, it may\n","\ttake up to 24 hours to be able to view or download the file. If you\n","\tstill can't access a file after 24 hours, contact your domain\n","\tadministrator.\n","\n","You may still be able to access the file from the browser:\n","\n","\thttps://drive.google.com/uc?id=1AQ4tusHvPgu09zn-j7rsvD_739OJtiGp\n","\n","but Gdown can't. Please check connections and permissions.\n"]}],"source":["!gdown https://drive.google.com/file/d/1AQ4tusHvPgu09zn-j7rsvD_739OJtiGp/view?usp=sharing --fuzzy"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ikNF3Vj_0nT","executionInfo":{"status":"ok","timestamp":1723776586165,"user_tz":-480,"elapsed":24,"user":{"displayName":"Hanyu Beh","userId":"09674366287163471345"}},"outputId":"d9e22996-71dc-483d-f0c3-de7fb49a210f"},"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open data_kaggle_week4.zip, data_kaggle_week4.zip.zip or data_kaggle_week4.zip.ZIP.\n"]}],"source":["!unzip -q data_kaggle_week4.zip"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"dn9fOkEguNwv","executionInfo":{"status":"ok","timestamp":1723776586165,"user_tz":-480,"elapsed":16,"user":{"displayName":"Hanyu Beh","userId":"09674366287163471345"}}},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"rwTUzYB7_8Ec","executionInfo":{"status":"error","timestamp":1723776586166,"user_tz":-480,"elapsed":15,"user":{"displayName":"Hanyu Beh","userId":"09674366287163471345"}},"outputId":"dc0cde91-e793-4514-f4a0-fdbed79190ea","colab":{"base_uri":"https://localhost:8080/","height":349}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'data_kaggle_week4'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-5e652a163e26>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_kaggle_week4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataweek4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWEEK4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_kaggle_week4'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import torch\n","import os\n","import numpy as np\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.transforms import ToTensor\n","from torchvision.utils import make_grid\n","from torch.utils.data.dataloader import DataLoader\n","from torch.utils.data import random_split\n","from torchvision.transforms import transforms\n","from data_kaggle_week4.dataweek4 import WEEK4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWW8MKkVI_Xh","executionInfo":{"status":"aborted","timestamp":1723776586167,"user_tz":-480,"elapsed":12,"user":{"displayName":"Hanyu Beh","userId":"09674366287163471345"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8b7i8gsdZbA","executionInfo":{"status":"aborted","timestamp":1723776586168,"user_tz":-480,"elapsed":13,"user":{"displayName":"Hanyu Beh","userId":"09674366287163471345"}}},"outputs":[],"source":["import random\n","def seed_all(seed=1029):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","seed_all(1029)"]},{"cell_type":"markdown","metadata":{"id":"TJZYOkYKFUsj"},"source":["## Data Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GPf3edp0Xcgj"},"outputs":[],"source":["## data augmentation\n","test_transform = transforms.Compose([transforms.ToTensor(),\n","                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize the images, each R,G,B value is normalized with mean=0.5 and std=0.5\n","                                     transforms.Resize((96,96)),  #resises the image so it can be perfect for our model.\n","                                     ])\n","\n","train_transform = transforms.Compose([transforms.Resize((96,96)),  #resises the image so it can be perfect for our model.\n","                                      transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n","                                      #transforms.RandomRotation(4),     #Rotates the image to a specified angel\n","                                      #transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n","                                    #  transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n","                                      transforms.ToTensor(), # convert the image to tensor so that it can work with torch\n","                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize the images, each R,G,B value is normalized with mean=0.5 and std=0.5\n","                                      ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zA7JBIeyDUaL"},"outputs":[],"source":["dataset = WEEK4(root='data_kaggle_week4', transform=ToTensor())\n","test_dataset = WEEK4(root='data_kaggle_week4', split ='test', transform=ToTensor())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7SQRKrWYDfDB"},"outputs":[],"source":["dataset_size = len(dataset)\n","train_ds = dataset\n","print('Train info', dataset_size, train_ds.data.shape)\n","\n","test_dataset_size = len(test_dataset)\n","print('Test info: ', test_dataset_size)\n","\n","classes = dataset.classes\n","print('Class info: ', dataset.classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIVgMdT9FUsk"},"outputs":[],"source":["img, label = dataset[0]\n","plt.imshow(img.permute((1, 2, 0)))\n","print('Label (numeric):', label)\n","print('Label (textual):', classes[label])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkTrTUk1FUsk"},"outputs":[],"source":["count_class = {}\n","for _,outs in dataset:\n","    labels = classes[outs]\n","    if labels not in count_class:\n","        count_class[labels] = 0\n","    count_class[labels] += 1\n","count_class"]},{"cell_type":"markdown","metadata":{"id":"0_LFaHNhGQeZ"},"source":["### Data Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kWf8O_4GQeZ"},"outputs":[],"source":["val_size = 1000\n","train_size = len(dataset) - val_size\n","train_ds, val_ds = random_split(dataset, [train_size, val_size])\n","len(train_ds), len(val_ds)"]},{"cell_type":"markdown","metadata":{"id":"CWTHJvdVGQeZ"},"source":["#### Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoGqUkRRGQeZ"},"outputs":[],"source":["batch_size=32\n","train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n","valid_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"]},{"cell_type":"markdown","metadata":{"id":"rwdDbM6gGQea"},"source":["#### Examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tE8_4bZBGQea"},"outputs":[],"source":["for images, _ in train_loader:\n","    print('images.shape:', images.shape)\n","    plt.figure(figsize=(16,8))\n","    plt.axis('off')\n","    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n","    break"]},{"cell_type":"markdown","metadata":{"id":"FENpITvPGQea"},"source":["## Define Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xH0gwrbvGQea"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def compute_loss(model, loss_fn, loader):\n","  loss = 0\n","  # Set model to eval mode for inference\n","  model.eval()\n","  with torch.no_grad():  # No need to track gradients for validation\n","    for (batchX, batchY) in loader:\n","      # Move data to the same device as the model\n","      batchX, batchY = batchX.to(device).type(torch.float32), batchY.to(device).type(torch.long)\n","      loss += loss_fn(model(batchX), batchY)\n","  # Set model back to train mode\n","  model.train()\n","  return float(loss)/len(loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TR4P9aAzGQea"},"outputs":[],"source":["def compute_acc(model, loader):\n","    correct = 0\n","    totals = 0\n","    # Set model to eval mode for inference\n","    model.eval()\n","    for (batchX, batchY) in loader:\n","        # Move batchX and batchY to the same device as the model\n","        batchX, batchY = batchX.to(device).type(torch.float32), batchY.to(device)\n","        outputs = model(batchX)  # feed batch to the model\n","        totals += batchY.size(0)  # accumulate totals with the current batch size\n","        predicted = torch.argmax(outputs.data, 1)  # get the predicted class\n","        # Move batchY to the same device as predicted for comparison\n","        correct += (predicted == batchY).sum().item()\n","    return correct / totals"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zCrHCWoCGQea"},"outputs":[],"source":["import time\n","def fit(model= None, train_loader = None, valid_loader= None, optimizer = None,\n","        num_epochs = 50, verbose = True):\n","  # Move the model to the device before initializing the optimizer\n","  model.to(device)\n","  if optimizer == None:\n","    optim = torch.optim.Adam(model.parameters(), lr = 0.001) # Now initialize optimizer with model on GPU\n","  else:\n","    optim = optimizer\n","  history = dict()\n","  history['val_loss'] = list()\n","  history['val_acc'] = list()\n","  history['train_loss'] = list()\n","  history['train_acc'] = list()\n","\n","  for epoch in range(num_epochs):\n","      start = time.time()\n","      model.train()\n","      for (X, y) in train_loader:\n","          # Move input data to the same device as the model\n","          X,y = X.to(device), y.to(device)\n","          # Forward pass\n","          outputs = model(X.type(torch.float32))\n","          loss = loss_fn(outputs, y.type(torch.long))\n","          # Backward and optimize\n","          optim.zero_grad()\n","          loss.backward()\n","          optim.step()\n","      #losses and accuracies for epoch\n","      val_loss = compute_loss(model, loss_fn, valid_loader)\n","      val_acc = compute_acc(model, valid_loader)\n","      train_loss = compute_loss(model, loss_fn, train_loader)\n","      train_acc = compute_acc(model, train_loader)\n","      history['val_loss'].append(val_loss)\n","      history['val_acc'].append(val_acc)\n","      history['train_loss'].append(train_loss)\n","      history['train_acc'].append(train_acc)\n","      end = time.time()\n","      print(f\"total time for each epoch {end - start}\") # time in seconds\n","      if not verbose: #verbose = True means we do show the training information during training\n","        print(f\"Epoch {epoch+1}/{num_epochs}\")\n","        print(f\"train loss= {train_loss:.4f} - train acc= {train_acc*100:.2f}% - valid loss= {val_loss:.4f} - valid acc= {val_acc*100:.2f}%\")\n","  return history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MmPbreigIJ5t"},"outputs":[],"source":["class CnnModel(nn.Module):\n","\tdef __init__(self):\n","\t\tsuper().__init__(num_classes=10)\n","\t\tself.network = nn.Sequential(\n","\t\t\tnn.Conv2d(3, 32, kernel_size=3, padding=1),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.MaxPool2d(2, 2), # output: 64 x 48 x 48\n","\n","\t\t\tnn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.MaxPool2d(2, 2), # output: 128 x 24 x 24\n","\n","\t\t\tnn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.MaxPool2d(2, 2), # output: 256 x 12 x 12\n","\t\t\tnn.Conv2d(256,512, kernel_size=3, stride=1, padding=1),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.MaxPool2d(2, 2), # output: 512 x 6 x 6\n","\t\t\tnn.Flatten(),\n","\t\t\tnn.Linear(512*6*6, 1024),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.Linear(1024, 512),\n","\t\t\tnn.ReLU(),\n","\t\t\tnn.Linear(512, num_classes))\n","\n","\tdef forward(self, xb):\n","\t\treturn self.network(xb)\n","\n","\n","def conv_block(in_channels, out_channels, pool=False):\n","\tlayers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","\t\t\t  nn.BatchNorm2d(out_channels),\n","\t\t\t  nn.ReLU(inplace=True)]\n","\tif pool: layers.append(nn.MaxPool2d(2))\n","\treturn nn.Sequential(*layers)\n","\n","class ResNet9(nn.Module):\n","\tdef __init__(self, in_channels=3, num_classes=10):\n","\t\tsuper().__init__()\n","\n","\t\tself.conv1 = conv_block(in_channels, 64,pool=True)\n","\t\tself.conv2 = conv_block(64, 128, pool=True) # output: 128 x 24 x 24\n","\t\tself.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n","\n","\t\tself.conv3 = conv_block(128, 256, pool=True) # output: 256 x 12 x 12\n","\t\tself.conv4 = conv_block(256, 512, pool=True) # output: 512 x 6 x 6\n","\t\tself.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n","\n","\t\tself.classifier = nn.Sequential(nn.MaxPool2d(6),\n","\t\t\t\t\t\t\t\t\t\tnn.Flatten(),\n","\t\t\t\t\t\t\t\t\t\tnn.Dropout(0.2),\n","\t\t\t\t\t\t\t\t\t\tnn.Linear(512, num_classes))\n","\n","\tdef forward(self, xb):\n","\t\tout = self.conv1(xb)\n","\t\tout = self.conv2(out)\n","\t\tout = self.res1(out) + out\n","\t\tout = self.conv3(out)\n","\t\tout = self.conv4(out)\n","\t\tout = self.res2(out) + out\n","\t\tout = self.classifier(out)\n","\t\treturn out\n","\n","class MiniVGG(nn.Module):\n","\tdef __init__(self, num_classes=10):\n","\t\tsuper().__init__()\n","\t\tlayers = []\n","\t\tlayers.append(nn.Conv2d(3, 32, kernel_size=3, padding= 1)) #[32,32,32]\n","\t\tlayers.append(nn.BatchNorm2d(32))\n","\t\tlayers.append(nn.ReLU(inplace=True))\n","\t\t#nn.LazyConv2d(32, kernel_size=3, padding=1),\n","\t\tlayers.append(nn.Conv2d(32, 32, kernel_size=3, padding=1)) #[32,32,32]\n","\t\tlayers.append(nn.BatchNorm2d(32))\n","\t\tlayers.append(nn.ReLU(inplace = True))\n","\t\tlayers.append(nn.MaxPool2d(kernel_size=2)) #down-sample by two #[32,16,16]\n","\t\tlayers.append(nn.Dropout(p=0.25))\n","\t\t#nn.LazyConv2d(64, kernel_size=3, padding=1),\n","\t\tlayers.append(nn.Conv2d(32, 64 , kernel_size=3, padding=1)) #[64,16,16]\n","\t\tlayers.append(nn.BatchNorm2d(64))\n","\t\tlayers.append(nn.ReLU(inplace = True))\n","\t\t#nn.LazyConv2d(64, kernel_size=3, padding=1)\n","\t\tlayers.append(nn.Conv2d(64, 64, kernel_size=3, padding=1)) #[64,16,16]\n","\t\tlayers.append(nn.BatchNorm2d(64))\n","\t\tlayers.append(nn.ReLU(inplace = True))\n","\t\tlayers.append(nn.Conv2d(64, 64, kernel_size=3, padding=1)) #[64,16,16]\n","\t\tlayers.append(nn.BatchNorm2d(64))\n","\t\tlayers.append(nn.ReLU(inplace= True)),\n","\t\tlayers.append(nn.MaxPool2d(kernel_size=2)), #down-sample by two [64,8,8]\n","\t\tlayers.append(nn.Dropout(p=0.25))\n","\t\tlayers.append(nn.Flatten(1)) #64x8x8\n","\t\tlayers.append(nn.LazyLinear(512))\n","\t\tlayers.append(nn.ReLU(inplace = True))\n","\t\tlayers.append(nn.LazyLinear(num_classes))\n","\t\tself.block = nn.ModuleList(layers)\n","\tdef forward(self,x):\n","\t\tfor layer in self.block:\n","\t\t\tx = layer(x)\n","\t\treturn x"]},{"cell_type":"markdown","metadata":{"id":"m8-d-P6pGQea"},"source":["## Training the Model"]},{"cell_type":"markdown","metadata":{"id":"9bzAenofGQea"},"source":["### Model Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRAl8Iy1GQea"},"outputs":[],"source":["model = ResNet9().to(device)\n","# model = MiniVGG(10).to(device)\n","# model = CnnModel().to(device)"]},{"cell_type":"markdown","metadata":{"id":"L23sZjWhGQeb"},"source":["#### <span style=\"color:#0b486b\">4. Declaring the Loss, Optimizer, learning rate and Training the Model </span>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TwNV7mPdGQeb"},"outputs":[],"source":["from torch import optim\n","optim_dict = {\"Adam\":optim.Adam, \"Adadelta\":optim.Adadelta, \"Adagrad\":optim.Adagrad,\n","              \"Adamax\":optim.Adamax, \"AdamW\": optim.AdamW, \"ASGD\":optim.ASGD,\n","              \"NAdam\":optim.NAdam, \"RMSprop\":optim.RMSprop, \"RAdam\":optim.RAdam,\n","              \"Rprop\": optim.Rprop, \"SGD\":optim.SGD}\n","\n","\n","# Loss and optimizer\n","learning_rate = 0.01\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim_dict[\"SGD\"](model.parameters(), lr=learning_rate)\n","\n","#dnn_model = model\n","history = fit(model=model, train_loader=train_loader, valid_loader = valid_loader,\n","    optimizer = optimizer, num_epochs= 2, verbose = False)"]},{"cell_type":"markdown","metadata":{"id":"O3-WS91yTvEL"},"source":["#### <span style=\"color:#0b486b\">5. Visualizing the Performance and Loss Objective Function </span>\n","\n","There are four keys in the history dictionary: `train_loss` and `val_loss` measure the loss on the training set and the validation set, respectively, while `train_acc` and `val_acc` measure the accuracy on the training set and the validation set.  \n","The following figure visualize all four metrics with two y-axes, losses (blue lines, in descending) and accuracies (red lines, in asending)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZVEdlONTuJR"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","his = history\n","fig = plt.figure(figsize=(8, 5))\n","ax = fig.add_subplot(111)\n","ln1 = ax.plot(his['train_loss'], 'r--',label='train_loss')\n","ln2 = ax.plot(his['val_loss'], 'b-',label='val_loss')\n","ax.set_ylabel('loss', color='blue')\n","ax.tick_params(axis='y', colors=\"blue\")\n","\n","lns = ln1 + ln2\n","labels = [l.get_label() for l in lns]\n","ax.legend(lns, labels, loc=7)\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"qNjeT-EyiRx3"},"source":["# Evaluate model on the testing set, get the csv file and upload to kaggle website."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"180qpEBIFUsl"},"outputs":[],"source":["import torch\n","import pandas as pd\n","\n","def save_prediction_to_csv(model, loader, device, output_file=\"submission.csv\"):\n","    model.eval()\n","    predictions = []\n","    image_ids = []\n","    df = {\n","    \"ImageId\": [],\n","    \"Label\": []\n","    }\n","    total = 0\n","    with torch.no_grad():\n","        for i, (batchX, batchY) in enumerate(loader):\n","            batchX, batchY = batchX.to(device), batchY.to(device)\n","            outputs = model(batchX.float())  # Convert to float32 and feed batch to the model\n","            predicted = torch.argmax(outputs, dim=1)  # Get the predicted class\n","            total += predicted.size(0)\n","            for ids, pred in enumerate(predicted):\n","                df[\"Label\"].append(pred.cpu().item())\n","    df[\"ImageId\"] = [i+1 for i in range(total)]\n","    # Create a DataFrame\n","    df = pd.DataFrame(df)\n","    # Save to CSV\n","    df.to_csv(output_file, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5573,"status":"ok","timestamp":1723728927259,"user":{"displayName":"Hanyu Beh","userId":"09674366287163471345"},"user_tz":-480},"id":"KR3gRHtsGTOm","outputId":"4e15638f-ba53-4888-c527-1506fc227c52"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["save_prediction_to_csv(model, test_loader, device)"]},{"cell_type":"markdown","metadata":{"id":"D3UicCvcFUsl"},"source":["# Upload result to kaggle competition"]},{"cell_type":"markdown","metadata":{"id":"lc9yWR-XFUsl"},"source":["## Regsiter Kaggle account using your private gmail\n","## Join the competition: [Kaggle Competition](https://www.kaggle.com/t/2488212ebd1d40c0a0915dbafdd9859e)\n","## Upload the submission.csv file to the kaggle website to get your results\n","\n","## Important: update your team name and team members' name in this XLS file: [Link to the XLS file](https://docs.google.com/spreadsheets/d/1LhxQ2lS-5dghUvgG9DyFSAZJFisvltclo675PKsg2k0/edit?usp=sharing)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4x1lE5gGQeb"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1XSQY0vp-ufqw7dX3_SqvZdFKrS1zN6yX","timestamp":1723699930671},{"file_id":"1srcg3XGz7PdbK8yE_APTKpRetTfL8sIg","timestamp":1723691971493},{"file_id":"1OcKWhjSIz0bfpgLmsW5ymHBDvWLeDQ3E","timestamp":1723618679757}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}